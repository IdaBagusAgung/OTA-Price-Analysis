"""
Automated Test: Multi-Model Comparison & Analytics Verification
================================================================
This script tests whether all 12 retrained models appear in:
1. Multi-model comparison table on result page
2. Analytics page with proper metrics (not zeros)
"""

import requests
import json
from datetime import datetime, timedelta

def test_prediction_endpoint():
    """Test prediction endpoint and verify multi-model comparison"""
    url = "http://localhost:5000/predict"
    
    # Test data - typical Airbnb booking
    check_in = (datetime.now() + timedelta(days=30)).strftime('%Y-%m-%d')
    check_out = (datetime.now() + timedelta(days=37)).strftime('%Y-%m-%d')
    
    payload = {
        'check_in': check_in,
        'check_out': check_out,
        'currency': 'USD',
        'locale': 'en-US',
        'nights': '7',
        'adults': '2',
        'children': '0',
        'infants': '0',
        'pets': '0'
    }
    
    print("=" * 80)
    print("ğŸ” TEST 1: PREDICTION ENDPOINT - MULTI-MODEL COMPARISON")
    print("=" * 80)
    print(f"ğŸ“… Test Booking: {payload['nights']} nights from {check_in} to {check_out}")
    print(f"ğŸ‘¥ Guests: {payload['adults']} adults")
    print(f"ğŸ’° Currency: {payload['currency']}")
    print("\nğŸš€ Sending prediction request...")
    
    try:
        response = requests.post(url, data=payload)
        
        if response.status_code == 200:
            # Check if it's HTML response (redirect to result page)
            if 'text/html' in response.headers.get('Content-Type', ''):
                print("âœ… Prediction successful - Got HTML result page")
                
                # Parse HTML to find model comparison table
                html = response.text
                
                # Count model names in comparison table
                expected_models = [
                    'Linear Regression', 'Ridge Regression', 'Lasso Regression',
                    'Decision Tree', 'SVR', 'KNN',
                    'Random Forest', 'Gradient Boosting', 'Extra Trees',
                    'XGBoost', 'LightGBM', 'CatBoost'
                ]
                
                found_models = []
                for model in expected_models:
                    if model.lower().replace(' ', '') in html.lower().replace(' ', ''):
                        found_models.append(model)
                
                print(f"\nğŸ“Š MODELS FOUND IN COMPARISON TABLE: {len(found_models)}/12")
                for i, model in enumerate(found_models, 1):
                    print(f"   {i}. âœ… {model}")
                
                missing_models = set(expected_models) - set(found_models)
                if missing_models:
                    print(f"\nâš ï¸  MISSING MODELS: {len(missing_models)}")
                    for model in missing_models:
                        print(f"   âŒ {model}")
                
                # Check for metrics in HTML (RÂ², RMSE, MAE)
                has_r2 = 'RÂ²' in html or 'R2' in html or 'rÂ²' in html
                has_rmse = 'RMSE' in html
                has_mae = 'MAE' in html
                
                print(f"\nğŸ“ˆ METRICS PRESENCE:")
                print(f"   {'âœ…' if has_r2 else 'âŒ'} RÂ² Score")
                print(f"   {'âœ…' if has_rmse else 'âŒ'} RMSE")
                print(f"   {'âœ…' if has_mae else 'âŒ'} MAE")
                
                # Check if there are actual price predictions (not zeros)
                has_predictions = '$' in html and any(char.isdigit() for char in html)
                print(f"\nğŸ’µ PRICE PREDICTIONS: {'âœ… Found' if has_predictions else 'âŒ Not Found'}")
                
                return len(found_models) == 12 and has_r2 and has_rmse and has_mae
            else:
                print("âŒ Expected HTML response but got:", response.headers.get('Content-Type'))
                return False
        else:
            print(f"âŒ Prediction failed with status code: {response.status_code}")
            print(f"Response: {response.text[:500]}")
            return False
            
    except Exception as e:
        print(f"âŒ Error testing prediction endpoint: {str(e)}")
        return False


def test_analytics_page():
    """Test analytics page for model metrics"""
    url = "http://localhost:5000/analytics"
    
    print("\n" + "=" * 80)
    print("ğŸ” TEST 2: ANALYTICS PAGE - MODEL METRICS")
    print("=" * 80)
    print("ğŸš€ Fetching analytics page...")
    
    try:
        response = requests.get(url)
        
        if response.status_code == 200:
            print("âœ… Analytics page loaded successfully")
            html = response.text
            
            # Check for model names in analytics
            expected_models = [
                'Linear Regression', 'Ridge Regression', 'Lasso Regression',
                'Decision Tree', 'SVR', 'KNN',
                'Random Forest', 'Gradient Boosting', 'Extra Trees',
                'XGBoost', 'LightGBM', 'CatBoost'
            ]
            
            found_models = []
            for model in expected_models:
                if model.lower().replace(' ', '') in html.lower().replace(' ', ''):
                    found_models.append(model)
            
            print(f"\nğŸ“Š MODELS IN ANALYTICS: {len(found_models)}/12")
            for i, model in enumerate(found_models, 1):
                print(f"   {i}. âœ… {model}")
            
            # Check for metrics
            has_r2 = 'RÂ²' in html or 'R2' in html
            has_rmse = 'RMSE' in html
            has_mae = 'MAE' in html
            has_accuracy = 'Accuracy' in html or 'accuracy' in html
            
            print(f"\nğŸ“ˆ METRICS ON ANALYTICS:")
            print(f"   {'âœ…' if has_r2 else 'âŒ'} RÂ² Score")
            print(f"   {'âœ…' if has_rmse else 'âŒ'} RMSE")
            print(f"   {'âœ…' if has_mae else 'âŒ'} MAE")
            print(f"   {'âœ…' if has_accuracy else 'âŒ'} Accuracy")
            
            # Check for non-zero values (look for percentages or decimal numbers)
            import re
            percentages = re.findall(r'\d+\.\d+%', html)
            decimals = re.findall(r'\d+\.\d+', html)
            
            has_real_values = len(percentages) > 0 or len(decimals) > 10
            print(f"\nğŸ’¯ REAL DATA VALUES: {'âœ… Found' if has_real_values else 'âŒ Only Zeros'}")
            if percentages:
                print(f"   ğŸ“Š Sample percentages: {percentages[:5]}")
            
            # Check for charts/visualizations
            has_charts = 'chart' in html.lower() or 'canvas' in html.lower()
            print(f"\nğŸ“Š CHARTS/VISUALIZATIONS: {'âœ… Present' if has_charts else 'âŒ Missing'}")
            
            return len(found_models) >= 10 and has_r2 and has_rmse and has_real_values
            
        else:
            print(f"âŒ Analytics page failed with status code: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Error testing analytics page: {str(e)}")
        return False


def main():
    """Run all tests and generate report"""
    print("\n")
    print("â•”" + "=" * 78 + "â•—")
    print("â•‘" + " " * 15 + "MULTI-MODEL COMPARISON TEST SUITE" + " " * 30 + "â•‘")
    print("â•‘" + " " * 78 + "â•‘")
    print("â•‘" + "  Testing all 12 retrained models appear in dashboard" + " " * 24 + "â•‘")
    print("â•‘" + "  Testing analytics shows real metrics (not zeros)" + " " * 26 + "â•‘")
    print("â•š" + "=" * 78 + "â•")
    
    # Run tests
    test1_passed = test_prediction_endpoint()
    test2_passed = test_analytics_page()
    
    # Generate summary
    print("\n" + "=" * 80)
    print("ğŸ“ TEST SUMMARY")
    print("=" * 80)
    print(f"Test 1 - Multi-Model Comparison: {'âœ… PASSED' if test1_passed else 'âŒ FAILED'}")
    print(f"Test 2 - Analytics Metrics: {'âœ… PASSED' if test2_passed else 'âŒ FAILED'}")
    print("=" * 80)
    
    if test1_passed and test2_passed:
        print("\nğŸ‰ ALL TESTS PASSED! Dashboard is working perfectly!")
        print("\nâœ… VERIFIED FEATURES:")
        print("   â€¢ All 12 models appear in multi-model comparison")
        print("   â€¢ Analytics page shows real metrics (not zeros)")
        print("   â€¢ RÂ², RMSE, MAE metrics present")
        print("   â€¢ Price predictions working")
        print("   â€¢ Charts and visualizations rendered")
        return 0
    else:
        print("\nâš ï¸  SOME TESTS FAILED - Please review output above")
        return 1


if __name__ == "__main__":
    exit(main())
